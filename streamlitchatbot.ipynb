{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-community langchain-huggingface faiss-cpu transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v_BVpYh3uyiC",
        "outputId": "95785a44-2830-421e-bb0a-98d83ece254a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.12/dist-packages (0.3.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.56.1-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.23)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.22.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (1.1.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.56.1-py3-none-any.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m146.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, transformers, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.0\n",
            "    Uninstalling transformers-4.56.0:\n",
            "      Successfully uninstalled transformers-4.56.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-community-0.3.29 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 transformers-4.56.1 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              },
              "id": "cfbc9bb5d9a54d8f9da4066d742af6a6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "nm_vFa7K_P8a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 1. Load knowledge base\n",
        "# ---------------------------\n",
        "loader = TextLoader(\"/content/abc.txt\")\n",
        "documents = loader.load()\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Split documents into chunks\n",
        "# ---------------------------\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Create embeddings\n",
        "# ---------------------------\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# ---------------------------\n",
        "# 4. Store in FAISS and create retriever\n",
        "# ---------------------------\n",
        "db = FAISS.from_documents(docs, embeddings)\n",
        "retriever = db.as_retriever()\n",
        "\n",
        "# ---------------------------\n",
        "# 5. LLM for generating answers\n",
        "# ---------------------------\n",
        "qa_pipeline = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=\"google/flan-t5-base\",\n",
        "    tokenizer=\"google/flan-t5-base\",\n",
        "    device=-1  # CPU\n",
        ")\n",
        "local_llm = HuggingFacePipeline(pipeline=qa_pipeline)\n",
        "\n",
        "# ---------------------------\n",
        "# 6. Conversational memory\n",
        "# ---------------------------\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# ---------------------------\n",
        "# 7. Create conversational retrieval chain\n",
        "# ---------------------------\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=local_llm,\n",
        "    retriever=retriever,\n",
        "    memory=memory\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# 8. Function to ask the bot\n",
        "# ---------------------------\n",
        "def ask_bot(query):\n",
        "    result = qa_chain({\"question\": query})\n",
        "    return result[\"answer\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1B9sixX-XiS",
        "outputId": "12929df8-99ea-4dde-ea5e-3b9614221d0f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3263407303.py:16: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n",
            "/tmp/ipython-input-3263407303.py:38: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 9. Test\n",
        "# ---------------------------\n",
        "print(\"User: What is LangChain?\")\n",
        "print(\"Bot:\", ask_bot(\"What is LangChain?\"))\n",
        "\n",
        "print(\"\\nUser: How does FAISS help in LangChain?\")\n",
        "print(\"Bot:\", ask_bot(\"How does FAISS help in LangChain?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce3jhACa-poQ",
        "outputId": "09e28138-d402-4259-9149-a9e26d0ab347"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: What is LangChain?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3263407303.py:53: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = qa_chain({\"question\": query})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot: LangChain is a framework for building applications with language models.\n",
            "\n",
            "User: How does FAISS help in LangChain?\n",
            "Bot: When a question is asked, LangChain retrieves relevant documents from FAISS to answer accurately.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"User: What i asked previously?\")\n",
        "print(\"Bot:\", ask_bot(\"What i asked previously?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJhPc65bASXx",
        "outputId": "52ecddf9-0ac1-427f-f16c-80d0e515b9e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: What i asked previously?\n",
            "Bot: LangChain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " .............."
      ],
      "metadata": {
        "id": "W_GM6FAml-83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Streamlit**"
      ],
      "metadata": {
        "id": "anEzP_Wxl5Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q streamlit pyngrok langchain transformers sentence-transformers\n",
        "\n",
        "import os\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Ngrok auth\n",
        "ngrok.set_auth_token(\"32TEOzn2ftdrPTyc9AWh4W8T1lQ_5iKmmMcL12aZfJUtum3Gc\")\n",
        "\n",
        "# Fixed port\n",
        "port = 8501\n",
        "os.environ[\"STREAMLIT_SERVER_PORT\"] = str(port)\n",
        "os.environ[\"STREAMLIT_SERVER_HEADLESS\"] = \"true\"\n",
        "\n",
        "# Write Streamlit app\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "import streamlit as st\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from transformers import pipeline\n",
        "\n",
        "st.set_page_config(page_title=\"Context-Aware Chatbot\")\n",
        "st.title(\"Context-Aware Chatbot (LangChain + FAISS)\")\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Load knowledge base\n",
        "loader = TextLoader(\"/content/abc.txt\")\n",
        "documents = loader.load()\n",
        "\n",
        "# 2. Split documents\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# 3. Create embeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# 4. FAISS retriever\n",
        "db = FAISS.from_documents(docs, embeddings)\n",
        "retriever = db.as_retriever()\n",
        "\n",
        "# 5. LLM\n",
        "qa_pipeline = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=\"google/flan-t5-base\",\n",
        "    tokenizer=\"google/flan-t5-base\",\n",
        "    device=-1\n",
        ")\n",
        "local_llm = HuggingFacePipeline(pipeline=qa_pipeline)\n",
        "\n",
        "# 6. Memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# 7. Conversational chain\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=local_llm,\n",
        "    retriever=retriever,\n",
        "    memory=memory\n",
        ")\n",
        "\n",
        "# 8. Bot function\n",
        "def ask_bot(query):\n",
        "    result = qa_chain({\"question\": query})\n",
        "    return result[\"answer\"]\n",
        "\n",
        "# ---------------------------\n",
        "# Streamlit UI\n",
        "if \"chat_history\" not in st.session_state:\n",
        "    st.session_state.chat_history = []\n",
        "\n",
        "query = st.text_input(\"You:\", \"\")\n",
        "\n",
        "if query:\n",
        "    answer = ask_bot(query)\n",
        "    st.session_state.chat_history.append((\"User\", query))\n",
        "    st.session_state.chat_history.append((\"Bot\", answer))\n",
        "\n",
        "for speaker, text in st.session_state.chat_history:\n",
        "    if speaker == \"User\":\n",
        "        st.markdown(f\"**You:** {text}\")\n",
        "    else:\n",
        "        st.markdown(f\"**Bot:** {text}\")\n",
        "\"\"\")\n",
        "\n",
        "# Start Streamlit in background\n",
        "get_ipython().system_raw(f\"streamlit run app.py &\")\n",
        "\n",
        "# Wait a few seconds for Streamlit to fully start\n",
        "time.sleep(5)\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(addr=port, proto=\"http\")\n",
        "print(f\"Your working Streamlit URL: {public_url}\")\n"
      ],
      "metadata": {
        "id": "nKL7wh_HgPRn",
        "outputId": "63349bf1-3d0d-4497-a238-6350dd14f2f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your working Streamlit URL: NgrokTunnel: \"https://91b4f1613a9d.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "print(ngrok.get_tunnels())\n",
        "ngrok.kill()  # stops all ngrok tunnels in this session"
      ],
      "metadata": {
        "id": "Y9-z_YEoi4vz",
        "outputId": "00177306-6318-4937-ebb2-a96a849361ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<NgrokTunnel: \"https://9800b476c732.ngrok-free.app\" -> \"http://localhost:8501\">, <NgrokTunnel: \"https://28348e3b57f9.ngrok-free.app\" -> \"http://localhost:8501\">, <NgrokTunnel: \"https://64020da6e9fa.ngrok-free.app\" -> \"http://localhost:8501\">]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}